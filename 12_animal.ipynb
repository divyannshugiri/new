{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "305d8eba-bf72-478a-948a-4ba2a00405ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19ec1a0a-d4fc-44b4-b380-212aa7ceecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your dataset directory\n",
    "data_dir = r\"C:\\Users\\Sanika_almale\\Desktop\\12 Animal\\raw-img\"  # Replace with your local dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11d71842-395e-41f8-95c7-0102eeb6bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MobileNetV2 model, excluding the top layer (output layer)\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2735872-b96a-4d02-80a2-ff462a78f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the base model to prevent updating the pre-trained weights during initial training\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32814189-a3f6-4d9c-882e-bb6fffd0dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new classification layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Add global average pooling layer\n",
    "x = Dense(128, activation='relu')(x)  # Add a fully-connected layer with 128 units\n",
    "output_layer = Dense(11, activation='softmax')(x)  # Adjust output layer for number of classes (change 10 if different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c83f9f1-782b-4cf4-9910-5e03a6ce5333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e7fb08-54e1-499b-a80a-cbce9f6111ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Adam optimizer and categorical crossentropy loss\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "817e16d3-822f-4042-b12c-dc505c319f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # Rescale the pixel values to [0, 1]\n",
    "    validation_split=0.2,  # Reserve 20% of the data for validation\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e19df0a-40c2-4d56-b267-6ac5c1ee748c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20995 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "# Prepare train and validation generators\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cef1f5d2-176f-4e37-ab60-5f50d0c93348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5244 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_gen = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b9644ef-8daa-4a76-9f44-4684e2d50c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a model checkpoint to save the best model based on validation loss\n",
    "checkpoint = ModelCheckpoint('best_animal_model.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7fd98d-19d2-4fd4-b3d7-86bcad7b59e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanika_almale\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8729 - loss: 0.4241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanika_almale\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.17748, saving model to best_animal_model.keras\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1522s\u001b[0m 2s/step - accuracy: 0.8730 - loss: 0.4239 - val_accuracy: 0.9424 - val_loss: 0.1775\n",
      "Epoch 2/5\n",
      "\u001b[1m136/657\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:57\u001b[0m 2s/step - accuracy: 0.9373 - loss: 0.1849"
     ]
    }
   ],
   "source": [
    "# Train the model for a few epochs\n",
    "history = model.fit(train_gen, validation_data=validation_gen, epochs=5, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4df4de-a469-4df7-aeff-3e42b87ca533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(validation_gen)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac1612-b7a0-4de4-8e29-67804a8265b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "x_val, y_val = next(validation_gen)  # Get a batch of validation data\n",
    "predictions = model.predict(x_val)\n",
    "predicted_labels = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388f29e9-b0b0-4618-a291-fa0bd47f3450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class labels\n",
    "class_labels = list(train_gen.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb5543-bd12-46f7-ba8d-8d670a5702d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted labels for the first 5 images\n",
    "n = 5\n",
    "plt.figure(figsize=(10, 20))\n",
    "for i in range(n):\n",
    "    plt.subplot(n, 1, i + 1)\n",
    "    plt.imshow(x_val[i])\n",
    "    actual_label = class_labels[np.argmax(y_val[i])]\n",
    "    predicted_label = class_labels[predicted_labels[i]]\n",
    "    plt.title(f\"Actual: {actual_label}, Predicted: {predicted_label}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cbb482-fb03-441e-a128-9c9044d05bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede624b2-4811-4d92-92bc-73b70c980949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
